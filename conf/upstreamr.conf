[dynamodb]
# Table that we will read our Upstream config from, in EM this is ConfigLBUpstream in DynamoDB
table=ConfigLBUpstream
# what is the key to recover, with our current schema is key, feel free to change if you modify the schema
key=key
# DynamoDB specific, we need to specify the comparison operators
# Most normal cases here are: contains, in
comparison_operator=contains
# This is the expression which will help us filter the keys we want,
# this is defined as a list (array) of environments that we want to configure
# You can create these in Environment Manager
filter_expression=["a01", "a02", "a03"]

[em]
# In case we want to use Environment Manager as our source of information
# This behaviour is managed in the [templates] -> data_source parameter
# Server that we will connect to, needs to have Environment Manager installed and SSL on
server=localhost
# User in Environment Manager that we use to authenticate ourselves
user=username
# Password for our authentication user
password=my_secure_password
# EM operation that we want to query from the API library
operation=get_upstreams_config
# EM operation parameters (can be empty {} if needed)
operation_paramaters = {}

[asg]
# Indicate if we want to use a DynamoDB table to publish DNS for ASGs
# We create this asg table as part of our Auto Scaling Groups deployment and add
# any IPs that belong to that ASG
# Boolean, set to true to enable the ASG thread
use_asg_dynamodb=true
# ASG file to write the results to, this will be consumed later by the template engine
asg_file=/tmp/asg_upstreamr.json
# Name of the table where we keep our ASG Ips
asg_table=AsgIpAddresses
# Key that we're looking for
asg_key=AsgName
# Value to recover
asg_value=IPs
# Every how many seconds we will be refreshing the information
refresh_rate=20
# Enable debug on thread
debug=false

[shutdown]
# Detect instance shutting down
# This will detect if an instance is already shutting down, this way we can remove it and not send traffic to it
detect_shutdown=true
# Shutdown file to write the results to, this will be consumed later by the template engine
shutdown_file=/tmp/shutdown_detect_upstreamr.json
# Every how many seconds we will be refreshing the information
refresh_rate=60
# Enable debug on thread
debug=false

[consul]
# Indicate if we want to use Consul to discover services
# We use Consul internally to publish services with consul-deployment-agent,
# this is our current preferred way to do it
# Boolean, set to true to enable this thread
use_consul=true
# Directory where we will write consul JSON files
# The format is consul_<DcName>.json
consul_file_dir=/tmp
# Consul mapping to be able to talk to Consul servers
# As Upstreamr can read from more than one Consul Datacenter
# we need to indicate which are the Master servers we can query
# also if we use tokens we can add our token here
# This is expressed as a list (array) always, and the format of
# it is: "<DcName>|<Environment>|<ConsulMasterIps>|<Token>"
# DcName: This is your Consul Datacentre name
# Environment: This is the list of your environments (semicolon separated) as defined on Environment Manager, can be more than one
# ConsulMasterIps: List (semicolon separated) of Consul Masters to access to, Upstreamr will try and cycle through them
# Token: The security Token from Consul you use if you want to access when security is enabled, leave empty otherwise
consul_mappings=["consul-datacenter|a01;a02|1.2.3.4;1.2.3.5|aaaa-token-aaa"]
# Every how many seconds we will be refreshing the information
refresh_rate=20
# Enable debug on thread
debug=false

[templates]
# This is the configuration for our main Template Thread
# Where we will generate all our files and notify services as needed
# Template Engine will compare all generated files for each run and
# rewrite any file that has changed
# It also has the ability to resolve DNS of any definition by using the
# internal function dns_resolve which is very useful for a stable nginx
# Which directory are we writing of templated files to
destination_directory=/etc/nginx/upstreamr.d
# What template do we need to generate those files
# it is based on Jinja2 (http://jinja.pocoo.org/docs/dev/templates/)
template_file=/etc/upstreamr/templates/nginx_upstream.template
# Where do we get our template info from (current options: em, dynamodb)
data_source=em
# This will be used to filter which results we will treat, its an array of valid objects. "all" is the magic word
data_filter=["a01", "a02", "a03"]
# Data operator, can either be startswith, contains, endswith or all as a magic word
data_operator=startswith
# This name will be built with the data_field and the {{}} as array members
filename_pattern={{ data['UpstreamName'] }}.upstream.conf
# Data field that we will pass onto the template to build everything, if set to "all" it'll pass the whole return
# data is a representation of data_field
data_field=value
# Json decode the data_field data
json_decode=true
# Reload if active slice has zero results
reload_zero_results=false
# SNS endpoints for alerting when we modify a file
reload_sns_notification_endpoints=
# Reload command after a file or files is/are modified
reload_command=/usr/sbin/service nginx reload
# SNS endpoints for alerting if the reload didnt work
reload_sns_alert_endpoints=
# Reload limit on every how many seconds we can reload nginx
reload_time_limit=20
## Reload limits for single upstream
# Every how many reload requests we declare this as a malfeasant (also we need the catching time below)
reload_single_upstream_limit_trigger=5
# What is the total reload exposure time (in seconds) for those reloads to set the trigger on, so for example we can say 5 reloads trigger in 120 seconds
reload_single_upstream_limit_trigger_catching_time=300
# Once this is triggered every how many seconds will we reload nginx for this upstream, something like every 5 mins perhaps?
reload_single_upstream_limit_time=1800
# After how many seconds we declare this service is not spurious and we can reset the trigger flag
reload_single_upstream_limit_cool_off_time=900
# Every how many seconds we run the Template Engine
refresh_rate=10
# Enable debug on thread
debug=false
